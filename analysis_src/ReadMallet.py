#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import argparse
import logging

class ReadMallet( object ):
	"""
	Convert mallet files into Termite internal format.
	"""
	
	# Files generated by Mallet
	TOPIC_WORD_WEIGHTS = 'topic-word-weights.txt'
	WORD_TOPIC_COUNTS = 'word-topic-counts.txt'
	
	def __init__( self, model_path, data_path, logging_level ):
		assert model_path is not None
		assert data_path is not None
		self.model_path = model_path
		self.data_path = data_path
		self.logger = logging.getLogger( 'ReadMallet' )
		self.logger.setLevel( logging_level )
		handler = logging.StreamHandler( sys.stderr )
		handler.setLevel( logging_level )
		self.logger.addHandler( handler )
	
	def execute( self, min_term_freq, min_term_count ):
		self.logger.info( '--------------------------------------------------------------------------------' )
		self.logger.info( 'Importing a Mallet model...'                                                      )
		self.logger.info( '    model = %s', self.model_path                                                  )
		self.logger.info( '    output = %s', self.data_path                                                  )
		self.logger.info( '    min_term_freq = %s', min_term_freq                                            )
		self.logger.info( '    min_term_count = %s', min_term_count                                          )
		
		self.logger.info( 'Reading "%s" from Mallet...', ReadMallet.TOPIC_WORD_WEIGHTS )
		self.ExtractTopicWordWeights( min_term_freq, min_term_count )
		
		self.logger.info( 'Writing data to disk...' )
		self.SaveToDisk()
		
		self.logger.info( '--------------------------------------------------------------------------------' )
	
	def ExtractTopicWordWeights( self, min_term_freq, min_term_count ):
		data = {}
		words = []
		topics = []
		wordWeights = {}
		wordCounts = {}
		
		# Read in content of file (sparse matrix representation)
		filename = '{}/{}'.format( self.model_path, ReadMallet.TOPIC_WORD_WEIGHTS )
		with open( filename ) as f:
			lines = f.read().decode( 'utf-8' ).splitlines()
			for line in lines:
				topic, word, value = line.split( '\t' )
				topic = int( topic, 10 )
				value = float( value )
				
				if topic not in data:
					data[ topic ] = {}
				data[ topic ][ word ] = value
				words.append( word )
				topics.append( topic )
				if word not in wordWeights:
					wordWeights[ word ] = 0.0
				wordWeights[ word ] += value
				if word not in wordCounts:
					wordCounts[ word ] = 0
				wordCounts[ word ] += 1
		
		# Get list of terms and topic indexes
		terms = sorted( list( frozenset( words ) ), key = lambda term : -wordWeights[ term ] )
		topics = sorted( list( frozenset( topics ) ), key = lambda topic : topic )
		
		# Filter terms
		terms = [ term for term in terms if wordWeights[ term ] >= min_term_freq and wordCounts[ term ] >= min_term_count ]
		
		# Build dense matrix representation
		matrix = []
		for term in terms :
			row = []
			for topic in topics :
				row.append( data[ topic ][ term ] )
			matrix.append( row )
		
		# Generate topic labels
		topic_str_index = [ 'Topic {}'.format(d+1) for d in topics ]
		
		self.matrix = matrix
		self.terms = terms
		self.topics = topic_str_index
	
	def SaveToDisk( self ):
		self.SaveTerms()
		self.SaveTopics()
		self.SaveTermTopicMatrix()
		
	def SaveTerms( self ):
		filename = '{}/term-index.txt'.format( self.data_path )
		with open( filename, 'w' ) as f:
			for term in self.terms:
				f.write( u'{}\n'.format( term ).encode( 'utf-8' ) )
			
	def SaveTopics( self ):
		filename = '{}/topic-index.txt'.format( self.data_path )
		with open( filename, 'w' ) as f:
			for topic in self.topics:
				f.write( u'{}\n'.format( topic ).encode( 'utf-8' ) )

	def SaveTermTopicMatrix( self ):
		filename = '{}/term-topic-matrix.txt'.format( self.data_path )
		with open( filename, 'w' ) as f:
			for row in self.matrix:
				f.write( u'{}\n'.format( '\t'.join( [ str( value ) for value in row ] ) ).encode( 'utf-8' ) )

def main():
	parser = argparse.ArgumentParser( description = 'Import results from Mallet topic model library into Termite.' )
	parser.add_argument( 'model_path', type = str, help = 'Mallet topic model output path.' )
	parser.add_argument( 'data_path' , type = str, help = 'Termit model data path.'         )
	parser.add_argument( '--term_freq', type = int, default = 20, help = 'Include only terms that occur at least this many times in the corpus.' )
	parser.add_argument( '--term_count', type = int, default = 5, help = 'Include only terms that appear in at least this many documents.' )
	parser.add_argument( '--logging' , type = int, default = 20, help = 'Override logging level.'         )
	args = parser.parse_args()
	
	ReadMallet( model_path = args.model_path, data_path = args.data_path, logging_level = args.logging ).execute( min_term_freq = args.term_freq, min_term_count = args.term_count )

if __name__ == '__main__':
	main()